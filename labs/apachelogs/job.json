{
  "id": "sessionize",
  "type": "script",
  "script": "val opts = Map(\n  \"zkhost\" -> \"localhost:9983\",\n  \"collection\" -> \"apachelogs\",\n  \"query\" -> \"+clientip:[* TO *] +ts:[* TO *] +bytes:[* TO *] +verb:[* TO *] +response:[* TO *]\",\n  \"split_field\" -> \"_version_\",\n  \"splits_per_shard\" -> \"4\",\n  \"fields\" -> \"id,_version_,clientip,ts,bytes,response,verb\")\n\nval logEvents = sqlContext.read.format(\"solr\").options(opts).load\nlogEvents.cache()\nlogEvents.registerTempTable(\"logs\")\n\nlogEvents.printSchema()\n\nsqlContext.udf.register(\"ts2ms\", (d: java.sql.Timestamp) => d.getTime)\n\nval sessions = sqlContext.sql(\n  \"\"\"\n    |SELECT *, sum(IF(diff_ms > 30000, 1, 0))\n    |OVER (PARTITION BY clientip ORDER BY ts) session_id\n    |FROM (SELECT *, ts2ms(ts) - lag(ts2ms(ts))\n    |OVER (PARTITION BY clientip ORDER BY ts) as diff_ms FROM logs) tmp\n  \"\"\".stripMargin)\nsessions.registerTempTable(\"sessions\")\nsessions.cache()\n\/\/sessions.select(\"clientip\", \"session_id\", \"ts\").show(100)\n\nval sessionsAgg = sqlContext.sql(\n  \"\"\"\n        |SELECT concat_ws('||', clientip,session_id) as id,\n        |       first(clientip) as clientip,\n        |       min(ts) as session_start,\n        |       max(ts) as session_end,\n        |       (ts2ms(max(ts)) - ts2ms(min(ts))) as session_len_ms_l,\n        |       sum(bytes) as total_bytes_l,\n        |       count(*) as total_requests_l\n        |FROM sessions\n        |GROUP BY clientip,session_id\n  \"\"\".stripMargin)\n\nsessionsAgg.printSchema()\n\nsessionsAgg.write.format(\"solr\").options(Map(\"zkhost\" -> \"localhost:9983\", \"collection\" -> \"apachelogs_signals_aggr\")).mode(org.apache.spark.sql.SaveMode.Overwrite).save"
}
